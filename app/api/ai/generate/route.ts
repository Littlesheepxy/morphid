import { NextRequest, NextResponse } from "next/server"
import { generateWithBestAvailableModel } from "@/lib/ai-models"
import { z } from "zod"

// é¢„å®šä¹‰çš„ schema æ˜ å°„
const SCHEMA_MAP = {
  intentResponse: z.object({
    identified: z.object({
      user_role: z.string().nullable(),
      use_case: z.string().nullable(),
      style: z.string().nullable(),
      highlight_focus: z.array(z.string()).default([])
    }),
    follow_up: z.object({
      missing_fields: z.array(z.string()).default([]),
      suggestions: z.record(z.object({
        prompt_text: z.string(),
        options: z.array(z.string())
      })).default({})
    }),
    completion_status: z.enum(['collecting', 'optimizing', 'ready']),
    direction_suggestions: z.array(z.string()).default([]),
    smart_defaults: z.any().default({})
  }),
  
  // å¯ä»¥æ·»åŠ æ›´å¤šé¢„å®šä¹‰çš„ schema
  recipe: z.object({
    name: z.string(),
    ingredients: z.array(z.object({
      name: z.string(),
      amount: z.string()
    })),
    steps: z.array(z.string())
  })
}

// TODO: æ€§èƒ½ä¼˜åŒ–é€‰é¡¹
// 1. æ·»åŠ  Redis ç¼“å­˜å±‚ç”¨äºç›¸ä¼¼è¯·æ±‚
// 2. å®ç°è¯·æ±‚å»é‡ï¼ˆç›¸åŒ prompt çš„å¹¶å‘è¯·æ±‚ï¼‰
// 3. æ·»åŠ å“åº”å‹ç¼©
// 4. å®ç°æµå¼å“åº”ä»¥æå‡ç”¨æˆ·ä½“éªŒ

export async function POST(request: NextRequest) {
  const requestStartTime = new Date();
  try {
    console.log(`\nğŸŒ [AI API] æ¥æ”¶åˆ°æ–°è¯·æ±‚ (${requestStartTime.toISOString()})`);
    
    const { prompt, messages, options } = await request.json()

    // ğŸ†• æ”¯æŒä¸¤ç§æ¨¡å¼ï¼šå•æ¬¡ prompt æˆ–å¯¹è¯å†å²
    if (!prompt && !messages) {
      console.log(`âŒ [å‚æ•°é”™è¯¯] ç¼ºå°‘ prompt æˆ– messages å‚æ•°`);
      return NextResponse.json(
        { success: false, error: "Prompt or messages is required" },
        { status: 400 }
      )
    }

    console.log(`ğŸ¤– [è¯·æ±‚åˆ†æ] AI API route - å¤„ç†è¯·æ±‚:`, { 
      mode: messages ? 'conversation' : 'single',
      promptLength: prompt?.length || 0,
      messagesCount: messages?.length || 0,
      hasSchema: !!options?.schema,
      schemaType: options?.schemaType,
      maxTokens: options?.maxTokens 
    });

    if (messages) {
      console.log(`ğŸ’¬ [å¯¹è¯æ¨¡å¼] æ¶ˆæ¯è¯¦æƒ…:`);
      messages.forEach((msg: any, index: number) => {
        const roleIcon = msg.role === 'user' ? 'ğŸ‘¤' : msg.role === 'assistant' ? 'ğŸ¤–' : 'ğŸ“';
        const roleName = msg.role === 'user' ? 'ç”¨æˆ·' : msg.role === 'assistant' ? 'åŠ©æ‰‹' : 'ç³»ç»Ÿ';
        console.log(`  ${roleIcon} [${roleName}${index}] ${msg.content?.substring(0, 150)}...`);
      });
    }

    // å¤„ç† schema - ä½¿ç”¨é¢„å®šä¹‰çš„ schema æ˜ å°„
    const processedOptions = { ...options }
    if (options?.schemaType && SCHEMA_MAP[options.schemaType as keyof typeof SCHEMA_MAP]) {
      console.log(`ğŸ”§ [Schemaå¤„ç†] ä½¿ç”¨é¢„å®šä¹‰ schema: ${options.schemaType}`)
      processedOptions.schema = SCHEMA_MAP[options.schemaType as keyof typeof SCHEMA_MAP]
    } else if (options?.schema) {
      // å¦‚æœç›´æ¥ä¼ é€’äº† schemaï¼Œç§»é™¤å®ƒï¼ˆå› ä¸º JSON åºåˆ—åŒ–ä¼šç ´å Zod schemaï¼‰
      console.log(`âš ï¸  [Schemaå¤„ç†] ç§»é™¤æ— æ•ˆçš„ schema å‚æ•°ï¼Œé™çº§ä¸ºæ–‡æœ¬ç”Ÿæˆ`)
      delete processedOptions.schema
    }

    // TODO: åœ¨è¿™é‡Œå¯ä»¥æ·»åŠ ç¼“å­˜æ£€æŸ¥
    // const cacheKey = generateCacheKey(prompt, processedOptions)
    // const cachedResult = await redis.get(cacheKey)
    // if (cachedResult) return NextResponse.json(cachedResult)

    // ğŸ†• æ ¹æ®æ¨¡å¼è°ƒç”¨ä¸åŒçš„ç”Ÿæˆæ–¹æ³•
    console.log(`ğŸš€ [æ¨¡å‹è°ƒç”¨] å‡†å¤‡è°ƒç”¨æ¨¡å‹ç”ŸæˆæœåŠ¡`);
    let result;
    if (messages) {
      console.log(`ğŸ’¬ [å¯¹è¯æ¨¡å¼] ä½¿ç”¨ messages æ•°ç»„è°ƒç”¨æ¨¡å‹`);
      // å¯¹è¯å†å²æ¨¡å¼
      result = await generateWithBestAvailableModel(messages, processedOptions);
    } else {
      console.log(`ğŸ“ [å•æ¬¡æ¨¡å¼] ä½¿ç”¨ prompt å­—ç¬¦ä¸²è°ƒç”¨æ¨¡å‹`);
      // å•æ¬¡ prompt æ¨¡å¼
      result = await generateWithBestAvailableModel(prompt, processedOptions);
    }

    const requestEndTime = new Date();
    const processingTime = requestEndTime.getTime() - requestStartTime.getTime();
    
    console.log(`âœ… [è¯·æ±‚å®Œæˆ] AI API è°ƒç”¨æˆåŠŸ:`, {
      processingTime: `${processingTime}ms`,
      resultType: typeof result,
      hasObject: 'object' in result,
      hasText: 'text' in result
    });

    // TODO: ç¼“å­˜ç»“æœ
    // await redis.setex(cacheKey, 3600, result) // ç¼“å­˜1å°æ—¶

    return NextResponse.json({
      success: true,
      data: result,
      timestamp: new Date().toISOString(),
      metadata: {
        processingTime,
        mode: messages ? 'conversation' : 'single'
      }
    })

  } catch (error) {
    const requestEndTime = new Date();
    const processingTime = requestEndTime.getTime() - requestStartTime.getTime();
    
    console.error(`âŒ [APIé”™è¯¯] AI ç”Ÿæˆå¤±è´¥:`, {
      error: error instanceof Error ? error.message : error,
      processingTime: `${processingTime}ms`,
      stack: error instanceof Error ? error.stack : undefined
    })
    
    const errorMessage = error instanceof Error ? error.message : "AI ç”Ÿæˆå¤±è´¥"
    
    return NextResponse.json(
      {
        success: false,
        error: errorMessage,
        suggestion: "è¯·æ£€æŸ¥ API key é…ç½®æˆ–ç½‘ç»œè¿æ¥",
        metadata: {
          processingTime
        }
      },
      { status: 500 }
    )
  }
} 