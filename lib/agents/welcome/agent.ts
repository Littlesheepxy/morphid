import { BaseAgent } from '../base-agent';
import { StreamableAgentResponse, AgentCapabilities } from '@/lib/types/streaming';
import { SessionData } from '@/lib/types/session';
import { generateWithModel, generateStreamWithModel } from '@/lib/ai-models';
import { 
  CollectedInfo,
  WelcomeAIResponse,
  WelcomeSummaryResult,
  getSystemPrompt,
  getFirstRoundPrompt,
  getContinuationPrompt,
  parseAIResponse,
  tryParseStreamingResponse,
  calculateCollectionProgress,
  buildConversationHistoryText,
  generateCollectionSummary,
  getSummaryPrompt,
  parseSummaryResponse
} from './utils';

/**
 * å¯¹è¯å¼Welcome Agent - çº¯å¯¹è¯æ”¶é›†ç”¨æˆ·ä¿¡æ¯
 * ä¸ä½¿ç”¨æŒ‰é’®äº¤äº’ï¼Œå®Œå…¨é€šè¿‡è‡ªç„¶å¯¹è¯æ”¶é›†æ‰€éœ€ä¿¡æ¯
 */
export class ConversationalWelcomeAgent extends BaseAgent {
  constructor() {
    const capabilities: AgentCapabilities = {
      canStream: true,
      requiresInteraction: false, // ä¸éœ€è¦æŒ‰é’®äº¤äº’
      outputFormats: ['json'],
      maxRetries: 2,
      timeout: 15000
    };
    
    super('ConversationalWelcomeAgent', capabilities);
  }

  /**
   * ä¸»å¤„ç†æµç¨‹ - çº¯å¯¹è¯å¼ä¿¡æ¯æ”¶é›†
   */
  async* process(
    input: { user_input: string },
    sessionData: SessionData,
    context?: Record<string, any>
  ): AsyncGenerator<StreamableAgentResponse, void, unknown> {
    console.log(`\nğŸ¤– [å¯¹è¯å¼Welcome Agent] å¼€å§‹å¤„ç†ç”¨æˆ·è¾“å…¥`);
    console.log(`ğŸ“ [ç”¨æˆ·è¾“å…¥] "${input.user_input}"`);
    
    try {
      // æ£€æŸ¥æ˜¯å¦æ˜¯é¦–è½®å¯¹è¯
      const metadata = sessionData.metadata as any;
      const conversationHistory = metadata.welcomeHistory || [];
      const currentInfo = metadata.collectedInfo || {};
      const isFirstRound = conversationHistory.length === 0;

      console.log(`ğŸ”„ [å¯¹è¯è½®æ¬¡] ${isFirstRound ? 'é¦–è½®' : 'ç¬¬' + (conversationHistory.length + 1) + 'è½®'}`);

      // æ„å»ºprompt
      let userPrompt: string;
      if (isFirstRound) {
        userPrompt = getFirstRoundPrompt(input.user_input);
      } else {
        const historyText = buildConversationHistoryText(conversationHistory);
        userPrompt = getContinuationPrompt(input.user_input, historyText, currentInfo);
      }

      console.log(`ğŸ¯ [å¤§æ¨¡å‹è°ƒç”¨] å‘é€æµå¼å¯¹è¯è¯·æ±‚`);
      
      // ğŸ†• æµå¼è°ƒç”¨å¤§æ¨¡å‹ï¼Œä½¿ç”¨Claudeå®˜æ–¹APIçš„æµå¼æ¨¡å¼
      let accumulatedResponse = '';
      let finalAiResponse: WelcomeAIResponse | null = null;
      let isFirstChunk = true;
      let messageId = `welcome-${Date.now()}`;
      
      for await (const chunk of this.callAIModelStreaming(userPrompt)) {
        accumulatedResponse += chunk;
        
        if (isFirstChunk) {
          // ğŸ¯ ç¬¬ä¸€ä¸ªå—ï¼šåˆ›å»ºæ–°æ¶ˆæ¯æ°”æ³¡å¹¶å¼€å§‹æµå¼è¾“å‡º
          yield this.createResponse({
            immediate_display: {
              reply: chunk,
              agent_name: this.name,
              timestamp: new Date().toISOString()
            },
            system_state: {
              intent: 'collecting',
              done: false,
              progress: 10,
              current_stage: 'ä¿¡æ¯æ”¶é›†ä¸­...',
              metadata: {
                streaming: true,
                message_id: messageId,
                stream_type: 'start'
              }
            }
          });
          isFirstChunk = false;
        } else {
          // ğŸ”„ åç»­å—ï¼šæ›´æ–°ç°æœ‰æ¶ˆæ¯æ°”æ³¡
          yield this.createResponse({
            immediate_display: {
              reply: accumulatedResponse,
              agent_name: this.name,
              timestamp: new Date().toISOString()
            },
            system_state: {
              intent: 'collecting',
              done: false,
              progress: Math.min(90, 10 + (accumulatedResponse.length / 10)),
              current_stage: 'ä¿¡æ¯æ”¶é›†ä¸­...',
              metadata: {
                streaming: true,
                message_id: messageId,
                stream_type: 'delta', // ğŸ”‘ å…³é”®ï¼šæ ‡è®°ä¸ºå¢é‡æ›´æ–°
                is_update: true // ğŸ”‘ å‘Šè¯‰å‰ç«¯è¿™æ˜¯æ›´æ–°ï¼Œä¸æ˜¯æ–°æ¶ˆæ¯
              }
            }
          });
        }
      }
      
      // ğŸ æµå¼å®Œæˆï¼šè§£ææœ€ç»ˆå“åº”å¹¶å‘é€å®ŒæˆçŠ¶æ€
      console.log(`ğŸ” [æµå¼å®Œæˆ] è§£ææœ€ç»ˆAIå“åº”`);
      finalAiResponse = parseAIResponse(accumulatedResponse);
      
      // å‘é€æµå¼å®Œæˆçš„æœ€ç»ˆçŠ¶æ€
      yield this.createResponse({
        immediate_display: {
          reply: finalAiResponse.reply,
          agent_name: this.name,
          timestamp: new Date().toISOString()
        },
        system_state: {
          intent: 'collecting',
          done: false,
          progress: calculateCollectionProgress(finalAiResponse.collected_info),
          current_stage: 'ä¿¡æ¯æ”¶é›†ä¸­',
          metadata: {
            streaming: false,
            message_id: messageId,
            stream_type: 'complete',
            is_update: true,
            completion_status: finalAiResponse.completion_status,
            collected_info: finalAiResponse.collected_info
          }
        }
      });
      
      // æ›´æ–°å¯¹è¯å†å²
      conversationHistory.push(
        { role: 'user', content: input.user_input },
        { role: 'assistant', content: finalAiResponse.reply }
      );
      
      // æ›´æ–°ä¼šè¯æ•°æ®
      metadata.welcomeHistory = conversationHistory;
      metadata.collectedInfo = { ...currentInfo, ...finalAiResponse.collected_info };
      
      console.log(`ğŸ’¾ [ä¿¡æ¯æ›´æ–°] å½“å‰æ”¶é›†çŠ¶æ€:`, metadata.collectedInfo);

      // æ ¹æ®å®ŒæˆçŠ¶æ€å†³å®šæœ€ç»ˆå“åº”
      if (finalAiResponse.completion_status === 'ready') {
        console.log(`ğŸ‰ [æ”¶é›†å®Œæˆ] ä¿¡æ¯æ”¶é›†å®Œæ•´ï¼Œå¼€å§‹æ±‡æ€»å¤„ç†`);
        
        // ğŸ†• è°ƒç”¨æ±‡æ€»åŠŸèƒ½
        const summaryResult = await this.generateSummary(conversationHistory);
        
        // ä¿å­˜æ±‡æ€»ç»“æœåˆ°ä¼šè¯æ•°æ®ï¼Œä¾›ä¸‹ä¸€ä¸ªAgentä½¿ç”¨
        metadata.welcomeSummary = summaryResult;
        
        yield this.createAdvanceResponse(finalAiResponse, summaryResult, sessionData);
      } else {
        console.log(`ğŸ”„ [ç»§ç»­æ”¶é›†] ç»§ç»­å¯¹è¯æ”¶é›†ä¿¡æ¯`);
        yield this.createContinueResponse(finalAiResponse, sessionData);
      }

    } catch (error) {
      console.error(`âŒ [å¯¹è¯å¼Welcome Agenté”™è¯¯] å¤„ç†å¤±è´¥:`, error);
      yield await this.handleError(error as Error, sessionData, context);
    }
  }

  /**
   * ğŸ†• æµå¼è°ƒç”¨AIæ¨¡å‹è¿›è¡Œå¯¹è¯
   */
  private async* callAIModelStreaming(userPrompt: string): AsyncGenerator<string, void, unknown> {
    try {
      yield* generateStreamWithModel(
        'claude',
        'claude-sonnet-4-20250514',
        [
          { role: 'system', content: getSystemPrompt() },
          { role: 'user', content: userPrompt }
        ],
        { maxTokens: 1000 }
      );
      
    } catch (error) {
      console.error('âŒ [AIæµå¼è°ƒç”¨å¤±è´¥]:', error);
      throw new Error('AIå¯¹è¯è°ƒç”¨å¤±è´¥');
    }
  }

  /**
   * è°ƒç”¨AIæ¨¡å‹è¿›è¡Œå¯¹è¯ï¼ˆä¿ç•™éæµå¼ç‰ˆæœ¬ä½œä¸ºå¤‡ç”¨ï¼‰
   */
  private async callAIModel(userPrompt: string): Promise<WelcomeAIResponse> {
    try {
      const result = await generateWithModel(
        'claude',
        'claude-sonnet-4-20250514',
        [
          { role: 'system', content: getSystemPrompt() },
          { role: 'user', content: userPrompt }
        ],
        { maxTokens: 1000 }
      );

      // è§£æAIå“åº”
      const resultText = 'text' in result ? result.text : JSON.stringify(result);
      const aiResponse = parseAIResponse(resultText);
      return aiResponse;
      
    } catch (error) {
      console.error('âŒ [AIè°ƒç”¨å¤±è´¥]:', error);
      throw new Error('AIå¯¹è¯è°ƒç”¨å¤±è´¥');
    }
  }

  /**
   * åˆ›å»ºç»§ç»­æ”¶é›†çš„å“åº”
   */
  private createContinueResponse(aiResponse: WelcomeAIResponse, sessionData: SessionData): StreamableAgentResponse {
    return this.createResponse({
      immediate_display: {
        reply: aiResponse.reply,
        agent_name: this.name,
        timestamp: new Date().toISOString()
      },
      system_state: {
        intent: 'collecting',
        done: false,
        progress: calculateCollectionProgress(aiResponse.collected_info),
        current_stage: 'ä¿¡æ¯æ”¶é›†ä¸­',
        metadata: {
          completion_status: 'collecting',
          collected_info: aiResponse.collected_info,
          next_question: aiResponse.next_question
        }
      }
    });
  }

  /**
   * ç”Ÿæˆä¿¡æ¯æ±‡æ€»
   */
  private async generateSummary(conversationHistory: any[]): Promise<WelcomeSummaryResult> {
    try {
      console.log(`ğŸ“Š [æ±‡æ€»å¤„ç†] å¼€å§‹ç”Ÿæˆä¿¡æ¯æ±‡æ€»...`);
      
      const summaryPrompt = getSummaryPrompt(conversationHistory);
      
      const result = await generateWithModel(
        'claude',
        'claude-sonnet-4-20250514',
        [
          { role: 'user', content: summaryPrompt }
        ],
        { maxTokens: 1000 }
      );

      const resultText = 'text' in result ? result.text : JSON.stringify(result);
      const summaryResult = parseSummaryResponse(resultText);
      
      console.log(`âœ… [æ±‡æ€»å®Œæˆ] ç”ŸæˆæˆåŠŸ:`, summaryResult.summary);
      return summaryResult;
      
    } catch (error) {
      console.error('âŒ [æ±‡æ€»å¤±è´¥]:', error);
      
      // é™çº§å¤„ç† - è¿”å›åŸºç¡€æ±‡æ€»
      return parseSummaryResponse('{}');
    }
  }

  /**
   * åˆ›å»ºæ¨è¿›åˆ°ä¸‹ä¸€é˜¶æ®µçš„å“åº”
   */
  private createAdvanceResponse(
    aiResponse: WelcomeAIResponse, 
    summaryResult: WelcomeSummaryResult,
    sessionData: SessionData
  ): StreamableAgentResponse {
    const collectedInfo = aiResponse.collected_info;
    const summary = generateCollectionSummary(collectedInfo);
    
    return this.createResponse({
      immediate_display: {
        reply: `${aiResponse.reply}\n\nğŸ‰ å¤ªæ£’äº†ï¼æˆ‘å·²ç»æ”¶é›†åˆ°æ‚¨çš„åŸºæœ¬ä¿¡æ¯ï¼š\n${summary}\n\nğŸš€ ç°åœ¨å¼€å§‹ä¸ºæ‚¨åˆ›å»ºä¸“å±çš„é¡µé¢ï¼`,
        agent_name: this.name,
        timestamp: new Date().toISOString()
      },
      system_state: {
        intent: 'advance_to_next',
        done: true,
        progress: 100,
        current_stage: 'ä¿¡æ¯æ”¶é›†å®Œæˆ',
        metadata: {
          completion_status: 'ready',
          collected_info: collectedInfo,
          // ğŸ†• æ·»åŠ æ±‡æ€»ç»“æœï¼ˆä¿æŒä¸processä¸­ä¸€è‡´çš„å­—æ®µåï¼‰
          welcomeSummary: summaryResult,
          action: 'advance',
          next_step: 'info_collection',
          // ğŸ†• ä¼ é€’ç»™ä¸‹ä¸€ä¸ªAgentçš„ä¸Šä¸‹æ–‡
          next_agent_context: summaryResult.context_for_next_agent
        }
      }
    });
  }

  /**
   * å¤„ç†ç”¨æˆ·äº¤äº’ - å¯¹è¯å¼Agentä¸éœ€è¦ç‰¹æ®Šäº¤äº’å¤„ç†
   */
  async handleInteraction(
    interactionType: string,
    data: any,
    sessionData: SessionData
  ): Promise<any> {
    // å¯¹è¯å¼Agentä¸éœ€è¦å¤„ç†æŒ‰é’®äº¤äº’
    // æ‰€æœ‰äº¤äº’éƒ½é€šè¿‡processæ–¹æ³•çš„å¯¹è¯å¤„ç†
    return {
      action: 'continue',
      summary: 'ç»§ç»­å¯¹è¯'
    };
  }
} 